{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "#!python -m spacy download de_core_news_md\n",
    "#!python -m spacy download en_core_web_lg \n",
    "en_nlp = spacy.load(\"en_core_web_lg\")\n",
    "#de_nlp = spacy.load(\"de_core_news_md\")\n",
    "\n",
    "import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "##from nltk import pos_tag, pos_tag_sents, word_tokenize, sent_tokenize\n",
    "##from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_deutsch = pd.read_csv(\"deutsch_stances.csv\", index_col = 0)\n",
    "df_deutsch.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_english = pd.read_csv(\"english_stances.csv\", index_col = 0)\n",
    "df_english.reset_index(inplace=True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        stems = []\n",
    "        for item in tokens:\n",
    "            if item.isdigit():\n",
    "                continue\n",
    "            elif item.isalnum():\n",
    "                stems.append(PorterStemmer().stem(item))\n",
    "        return stems\n",
    "\n",
    "def clean_text(text):\n",
    "    website_pattern = re.compile(r'\\((.*?)\\)') \n",
    "    slash_pattern = re.compile(r'[\\[\\]]')\n",
    "    text = re.sub(website_pattern, \"\", text)\n",
    "    text = re.sub(slash_pattern, \"\", text)\n",
    "    return text\n",
    "\n",
    "def generate_base(df, column, language, model = \"glove\"):\n",
    "    lang = \"en\" if language == \"english\" else \"de\"\n",
    "    \n",
    "    if model == \"glove\":\n",
    "        nlp = en_nlp if language == \"english\" else de_nlp\n",
    "        embeddings = np.array([nlp(x).vector for x in list(df[column].values)])\n",
    "        shape = embeddings.shape[1]\n",
    "        columns = [\"{}_dimension_{}\".format(column, i) for i in range(shape)]\n",
    "        ff = pd.DataFrame(data=embeddings, columns=columns)\n",
    "        \n",
    "    elif model == \"tfidf-stemmed\":\n",
    "        model = load(\"tfidf_\"+ lang +\"_stemmed.sav\")\n",
    "        data = model.transform(df[column])\n",
    "        columns = [column +\":\" + col for col in model.get_feature_names()]\n",
    "        ff = pd.SparseDataFrame(data = data, columns=columns).fillna(0)\n",
    "        \n",
    "    elif model == \"tfidf-unstemmed\":\n",
    "        model = load(\"tfidf_\"+ lang +\"_unstemmed.sav\")\n",
    "        data = model.transform(df[column])\n",
    "        columns = [column +\":\" + col for col in model.get_feature_names()]\n",
    "        ff = pd.SparseDataFrame(data = data, columns=columns).fillna(0)\n",
    "        \n",
    "    return ff\n",
    "\n",
    "def generate_additional(df, column, language, modes = [\"pos\", \"ner\", \"sentiment\"]):\n",
    "    nlp = en_nlp if language == \"english\" else de_nlp\n",
    "    docs = [nlp(x) for x in list(df[column].values)]\n",
    "    n = len(df)\n",
    "    dfs = []\n",
    "    \n",
    "    # use pos tags\n",
    "    if \"pos\" in modes:\n",
    "        # research tag by using spacy.explain: spacy.explain(\"ADP\")\n",
    "        pos_tags = {\"PRON\": [0]*n, \n",
    "                    \"ADV\": [0]*n, \n",
    "                    \"ADJ\": [0]*n, \n",
    "                    \"ADP\": [0]*n,\n",
    "                    \"DET\": [0]*n,\n",
    "                    \"AUX\": [0]*n,\n",
    "                    \"VERB\": [0]*n, \n",
    "                    \"NOUN\": [0]*n, \n",
    "                    \"PUNCT\": [0]*n, \n",
    "                    \"NUM\": [0]*n}\n",
    "\n",
    "        for i, doc in enumerate(docs):\n",
    "            for token in doc:\n",
    "                if token.pos_ in pos_tags.keys():\n",
    "                    pos_tags[token.pos_][i] += 1\n",
    "        tf = pd.DataFrame.from_dict(pos_tags)\n",
    "        tf.columns = [column +\":\" + col for col in tf.columns]\n",
    "        dfs.append(tf)\n",
    "    \n",
    "    # use sentiment tas: negative, neutral, positive and compound\n",
    "    if \"sentiment\" in modes:\n",
    "        sentiment = [sid.polarity_scores(x) for x in list(df[column].values)]\n",
    "        tf = pd.DataFrame(data=sentiment)\n",
    "        tf.columns = [column +\":\" + col for col in tf.columns]\n",
    "        dfs.append(tf)\n",
    "        \n",
    "    # use named entity recognition:\n",
    "    if \"ner\" in modes:\n",
    "        ner_types = {\"PERSON\": [0]*n, \n",
    "                    \"NORP\": [0]*n, \n",
    "                    \"FAC\": [0]*n, \n",
    "                    \"ORG\": [0]*n,\n",
    "                    \"GPE\": [0]*n,\n",
    "                    \"LOC\": [0]*n,\n",
    "                    \"PRODUCT\": [0]*n, \n",
    "                    \"EVENT\": [0]*n, \n",
    "                    \"WORK_OF_ART\": [0]*n, \n",
    "                    \"LAW\": [0]*n,\n",
    "                    \"LANGUAGE\": [0]*n, \n",
    "                    \"QUANITY\": [0]*n,\n",
    "                    \"ORDINAL\": [0]*n, \n",
    "                    \"CARDINAL\": [0]*n}\n",
    "        for i, doc in enumerate(docs):\n",
    "            for entity in doc.ents:\n",
    "                if entity.label_ in ner_types.keys():\n",
    "                    ner_types[entity.label_][i] += 1\n",
    "        tf = pd.DataFrame.from_dict(ner_types)\n",
    "        tf.columns = [column +\":\" + col for col in tf.columns]\n",
    "        dfs.append(tf)\n",
    "    if \"structure\" in modes:\n",
    "        pass\n",
    "    \n",
    "    return pd.concat(dfs, axis=1)\n",
    "\n",
    "def prep_dataset(df, model, language, modes = []):\n",
    "    dfs = []\n",
    "    df_stance = pd.concat([df['stance']], axis=1)\n",
    "    df_stance['stance'] = df_stance.stance.apply(lambda x: 1 if x == \"RA\" else 0)\n",
    "    dfs.append(df_stance)\n",
    "    #dfs.append(generate_base(df, \"child_text\", model=model, language=language))\n",
    "    #dfs.append(generate_base(df, \"parent_text\", model=model, language=language))\n",
    "    if modes != []:\n",
    "        dfs.append(generate_additional(df, \"child_text\", language=language, modes = modes))\n",
    "        dfs.append(generate_additional(df, \"parent_text\", language=language, modes = modes))\n",
    "    return pd.concat(dfs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 47s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stance</th>\n",
       "      <th>child_text:PRON</th>\n",
       "      <th>child_text:ADV</th>\n",
       "      <th>child_text:ADJ</th>\n",
       "      <th>child_text:ADP</th>\n",
       "      <th>child_text:DET</th>\n",
       "      <th>child_text:AUX</th>\n",
       "      <th>child_text:VERB</th>\n",
       "      <th>child_text:NOUN</th>\n",
       "      <th>child_text:PUNCT</th>\n",
       "      <th>...</th>\n",
       "      <th>parent_text:GPE</th>\n",
       "      <th>parent_text:LOC</th>\n",
       "      <th>parent_text:PRODUCT</th>\n",
       "      <th>parent_text:EVENT</th>\n",
       "      <th>parent_text:WORK_OF_ART</th>\n",
       "      <th>parent_text:LAW</th>\n",
       "      <th>parent_text:LANGUAGE</th>\n",
       "      <th>parent_text:QUANITY</th>\n",
       "      <th>parent_text:ORDINAL</th>\n",
       "      <th>parent_text:CARDINAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      stance  child_text:PRON  child_text:ADV  child_text:ADJ  child_text:ADP  \\\n",
       "0          1                0               0               2               1   \n",
       "1          1                0               2               5               5   \n",
       "2          0                0               2               2               3   \n",
       "3          1                0               0               2               4   \n",
       "4          1                0               0               2               4   \n",
       "...      ...              ...             ...             ...             ...   \n",
       "9995       0                0               2               2               2   \n",
       "9996       0                0               0               4               1   \n",
       "9997       1                0               0               3               1   \n",
       "9998       1                0               0               2               3   \n",
       "9999       1                0               0               3               3   \n",
       "\n",
       "      child_text:DET  child_text:AUX  child_text:VERB  child_text:NOUN  \\\n",
       "0                  3               1                1                3   \n",
       "1                  5               0                5               11   \n",
       "2                  4               1                4                7   \n",
       "3                  3               0                3                9   \n",
       "4                  2               0                1                6   \n",
       "...              ...             ...              ...              ...   \n",
       "9995               1               2                0               11   \n",
       "9996               0               0                0                6   \n",
       "9997               2               0                1                4   \n",
       "9998               1               0                0                7   \n",
       "9999               1               2                1                4   \n",
       "\n",
       "      child_text:PUNCT  ...  parent_text:GPE  parent_text:LOC  \\\n",
       "0                    1  ...                0                0   \n",
       "1                    2  ...                0                0   \n",
       "2                    1  ...                0                0   \n",
       "3                   11  ...                0                0   \n",
       "4                    4  ...                0                0   \n",
       "...                ...  ...              ...              ...   \n",
       "9995                 6  ...                0                0   \n",
       "9996                 1  ...                0                0   \n",
       "9997                 2  ...                0                0   \n",
       "9998                 4  ...                0                0   \n",
       "9999                 3  ...                0                0   \n",
       "\n",
       "      parent_text:PRODUCT  parent_text:EVENT  parent_text:WORK_OF_ART  \\\n",
       "0                       0                  1                        0   \n",
       "1                       0                  0                        0   \n",
       "2                       0                  1                        0   \n",
       "3                       0                  1                        0   \n",
       "4                       0                  1                        0   \n",
       "...                   ...                ...                      ...   \n",
       "9995                    0                  0                        0   \n",
       "9996                    0                  0                        0   \n",
       "9997                    0                  0                        0   \n",
       "9998                    0                  0                        0   \n",
       "9999                    0                  0                        0   \n",
       "\n",
       "      parent_text:LAW  parent_text:LANGUAGE  parent_text:QUANITY  \\\n",
       "0                   0                     0                    0   \n",
       "1                   0                     0                    0   \n",
       "2                   0                     0                    0   \n",
       "3                   0                     0                    0   \n",
       "4                   0                     0                    0   \n",
       "...               ...                   ...                  ...   \n",
       "9995                0                     0                    0   \n",
       "9996                0                     0                    0   \n",
       "9997                0                     0                    0   \n",
       "9998                0                     0                    0   \n",
       "9999                0                     0                    0   \n",
       "\n",
       "      parent_text:ORDINAL  parent_text:CARDINAL  \n",
       "0                       0                     0  \n",
       "1                       0                     0  \n",
       "2                       0                     0  \n",
       "3                       0                     0  \n",
       "4                       0                     0  \n",
       "...                   ...                   ...  \n",
       "9995                    0                     1  \n",
       "9996                    0                     0  \n",
       "9997                    0                     0  \n",
       "9998                    0                     0  \n",
       "9999                    0                     0  \n",
       "\n",
       "[10000 rows x 57 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = prep_dataset(df_english[:10000], model = \"glove\", language=\"english\", modes = [\"ner\", \"sentiment\", \"pos\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "# random state value\n",
    "rsv = 42\n",
    "# cpus used for training\n",
    "n_jobs = -1 \n",
    "\n",
    "models = {\"SVG\": SVC(probability=True,\n",
    "                    random_state=rsv),\n",
    "          \"LogReg\": LogisticRegression(random_state=rsv,\n",
    "                                      n_jobs=n_jobs),\n",
    "          \"RanFor\": RandomForestClassifier(random_state=rsv,\n",
    "                                          n_jobs=n_jobs),\n",
    "          \"GausNB\": GaussianNB(),\n",
    "          \"LDA\": LinearDiscriminantAnalysis(),\n",
    "          \"KNN\": KNeighborsClassifier(n_jobs=n_jobs)}\n",
    "\n",
    "# split in training data matrix X and target y\n",
    "def generate_cv_sets(df: pd.DataFrame):\n",
    "    X = df.loc[:, df.columns != 'stance']\n",
    "    y = df[['stance']].values.ravel()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_cv_sets(df)\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train.fillna(0), y_train)\n",
    "    score = model.score(X_test.fillna(0), y_test)\n",
    "    cf_matrix = metrics.confusion_matrix(y_test, model.predict(X_test.fillna(0)))\n",
    "    results[name] = {\"score\": score, \"cfm\": cf_matrix}\n",
    "    models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.602, array([[716, 551],\n",
       "        [444, 789]], dtype=int64))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = generate_cv_sets(df)\n",
    "results = {}\n",
    "model = LogisticRegression(random_state=42, n_jobs=-1)\n",
    "model.fit(X_train.fillna(0), y_train)\n",
    "score = model.score(X_test.fillna(0), y_test)\n",
    "cf_matrix = metrics.confusion_matrix(y_test, model.predict(X_test.fillna(0)))\n",
    "score, cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVG': {'score': 0.636, 'cfm': array([[159,   0],\n",
       "         [ 91,   0]], dtype=int64)},\n",
       " 'LogReg': {'score': 0.652, 'cfm': array([[130,  29],\n",
       "         [ 58,  33]], dtype=int64)},\n",
       " 'RanFor': {'score': 0.656, 'cfm': array([[137,  22],\n",
       "         [ 64,  27]], dtype=int64)},\n",
       " 'GausNB': {'score': 0.604, 'cfm': array([[124,  35],\n",
       "         [ 64,  27]], dtype=int64)},\n",
       " 'LDA': {'score': 0.6, 'cfm': array([[104,  55],\n",
       "         [ 45,  46]], dtype=int64)},\n",
       " 'KNN': {'score': 0.684, 'cfm': array([[138,  21],\n",
       "         [ 58,  33]], dtype=int64)}}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
